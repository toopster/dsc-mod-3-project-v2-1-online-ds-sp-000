{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science - Module 3 - Final Project Submission\n",
    "\n",
    "* Student Name: **James Toop**\n",
    "* Student Pace: **Self Paced**\n",
    "* Scheduled project review date/time: **TBC**\n",
    "* Instructor name: **Jeff Herman**\n",
    "* Blog post URL: **TBC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Business Case](#business-case)\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "    1. [Discovery](#data-discovery)\n",
    "    2. [Updated Field Descriptions](#updated-field-descriptions)\n",
    "    3. [Preprocessing](#data-preprocessing)\n",
    "    4. [Visualisations](#data-visualisations)\n",
    "    \n",
    "3. [Modelling](#modelling)\n",
    "    1. [Logistic Regression](#logistic-regression)\n",
    "    2. [Bagged Tree](#bagged-tree)\n",
    "    3. [Random Forest with GridSearchCV](#random-forest)\n",
    "    4. [XGBoost with GridSearchCV](#xgboost)\n",
    "    5. [Modelling Summary](#modelling-summary)\n",
    "    \n",
    "4. [Competition Submission File](#competition-submission-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"business-case\"></a>\n",
    "## 1. Business Case / Project Scope\n",
    "\n",
    "Tanzania has a water and sanitation crisis. Only 50% of the population of 53 million have access to an improved source of safe water, and 34% of the population has access to improved sanitation. The demand for both water and sanitation is high.\n",
    "\n",
    "Water is an essential of life, yet millions around the world still don’t have access to clean water. One of the most common causes of death in the developing world is drinking dirty and diseased water.\n",
    "\n",
    "Did you know 748 Million people in the world don’t have access to safe water?\n",
    "\n",
    "Water wells provide clean water for years. In rural areas, they are a lifeline for the inhabitants as this may be the only source of potable water.\n",
    "\n",
    "Using data from Taarifa and the Tanzanian Ministry of Water, can you predict which pumps are functional, \n",
    "which need some repairs, and which don't work at all? This is an intermediate-level practice competition. \n",
    "Predict one of these three classes based on a number of variables about what kind of pump is operating, \n",
    "when it was installed, and how it is managed. A smart understanding of which waterpoints will fail can improve \n",
    "maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
    "\n",
    "The goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided the following set of information about the waterpoints:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"eda\"></a>\n",
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"data-discovery\"></a>\n",
    "### 2A. Data Discovery\n",
    "\n",
    "This section presents an initial step to investigate, understand and document the available data fields and relationships, highlighting any potential issues / shortcomings within the datasets supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries for data discovery and exploratory data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set styles and color palette for Seaborn\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "traffic_light_palette = ['#4d8b26','#f2a81d','#cc3232']\n",
    "sns.set_palette(sns.color_palette(traffic_light_palette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the waterpoints training data file from the repository then inspect the data\n",
    "waterpoints = pd.read_csv('training-set-values.csv')\n",
    "waterpoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterpoints.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterpoints.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View unique values for category fields (Refactored to streamline repetitive code into a function)\n",
    "\n",
    "def output_field_values(fields):\n",
    "    for field in fields:        \n",
    "        field_values = np.sort(waterpoints[field].value_counts())\n",
    "        print(len(field_values),\"\\033[1m\",field,\"\\033[0m options:\\n\")\n",
    "        print(waterpoints[field].value_counts(normalize=True))\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "output_field_values(['scheme_management',\n",
    "                     'permit',\n",
    "                     'extraction_type',\n",
    "                     'extraction_type_group',\n",
    "                     'extraction_type_class',\n",
    "                     'management',\n",
    "                     'management_group',\n",
    "                     'payment',\n",
    "                     'payment_type',\n",
    "                     'water_quality',\n",
    "                     'quality_group',\n",
    "                     'quantity',\n",
    "                     'quantity_group',\n",
    "                     'source',\n",
    "                     'source_type',\n",
    "                     'source_class',\n",
    "                     'waterpoint_type',\n",
    "                     'waterpoint_type_group'\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterpoints['construction_year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterpoints['installer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how many NULL values are contained within the dataset and in which fields\n",
    "waterpoints.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the waterpoints training labels data file from the repository then inspect the data\n",
    "waterpoints_status = pd.read_csv('training-set-labels.csv')\n",
    "waterpoints_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterpoints_status['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(waterpoints_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"updated-field-descriptions\"></a>\n",
    "### 2B. Updated Field Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`amount_tsh`** : Total static head (amount of water available to waterpoint)\n",
    "* **`date_recorded`** : The date the row was entered\n",
    "* **`funder`** : Who funded the well\n",
    "* **`gps_height`** : Altitude of the well\n",
    "* **`installer`** : Organization that installed the well\n",
    "* **`longitude`** : GPS coordinate\n",
    "* **`latitude`** : GPS coordinate\n",
    "* **`wpt_name`** : Name of the waterpoint if there is one\n",
    "* **`num_private`** : NO FIELD DEFINITION, CONSIDER DROPPING\n",
    "* **`basin`** : Geographic water basin\n",
    "* **`subvillage`** : Geographic location\n",
    "* **`region`** : Geographic location\n",
    "* **`region_code`** : Geographic location (coded)\n",
    "* **`district_code`** : Geographic location (coded)\n",
    "* **`lga`** : Geographic location\n",
    "* **`ward`** : Geographic location\n",
    "* **`population`** : Population around the well : DATA APPEARS INCOSISTENT OR INCORRECT, CONSIDER DROPPING\n",
    "* **`public_meeting`** : NO FIELD DEFINITION, CONSIDER DROPPING\n",
    "    * True\n",
    "    * False\n",
    "* **`recorded_by`** : Group entering this row of data\n",
    "* **`scheme_management`** : Who operates the waterpoint\n",
    "    * VWC\n",
    "    * WUG\n",
    "    * Water authority\n",
    "    * WUA\n",
    "    * Water Board\n",
    "    * Parastatal\n",
    "    * Private operator\n",
    "    * Company\n",
    "    * Other\n",
    "    * SWC\n",
    "    * Trust\n",
    "    * None\n",
    "* **`scheme_name`** : Who operates the waterpoint : LARGE NUMBER OF NULL VALUES / RELEVANCE CONSIDER DROPPING\n",
    "* **`permit`** : If the waterpoint is permitted\n",
    "    * True\n",
    "    * False\n",
    "* **`construction_year`** : Year the waterpoint was constructed\n",
    "* **`extraction_type`** : The kind of extraction the waterpoint uses (brand names of pumps) : DETAIL OF **`extraction_type_group`** FIELD\n",
    "    * gravity\n",
    "    * nira/tanira\n",
    "    * other\n",
    "    * submersible\n",
    "    * swn 80\n",
    "    * mono\n",
    "    * india mark ii\n",
    "    * afridev\n",
    "    * ksb \n",
    "    * other - rope pump\n",
    "    * other - swn 81\n",
    "    * windmill\n",
    "    * india mark iii\n",
    "    * cemo\n",
    "    * other - play pump\n",
    "    * walimi\n",
    "    * climax\n",
    "    * other - mkulima/shinyanga\n",
    "* **`extraction_type_group`** : The kind of extraction the waterpoint uses : GROUPED CLASS OF **`extraction_type`** FIELD\n",
    "    * gravity\n",
    "    * nira/tanira\n",
    "    * other\n",
    "    * submersible\n",
    "    * swn 80\n",
    "    * mono\n",
    "    * india mark ii\n",
    "    * afridev\n",
    "    * rope pump\n",
    "    * other handpump\n",
    "    * other motorpump\n",
    "    * wind-powered\n",
    "    * india mark iii\n",
    "* **`extraction_type_class`** : The kind of extraction the waterpoint uses : GROUPED CLASS OF **`extraction_type`** FIELD\n",
    "    * gravity\n",
    "    * handpump\n",
    "    * other\n",
    "    * submersible\n",
    "    * motorpump\n",
    "    * rope pump\n",
    "    * wind-powered\n",
    "* **`management`** : How the waterpoint is managed : DETAIL OF **`management_group`** FIELD\n",
    "    * vwc\n",
    "    * wug\n",
    "    * water board\n",
    "    * wua\n",
    "    * private operator\n",
    "    * [parastatal](https://www.collinsdictionary.com/dictionary/english/parastatal)\n",
    "    * water authority\n",
    "    * other\n",
    "    * company\n",
    "    * unknown\n",
    "    * other - school\n",
    "    * trust\n",
    "* **`management_group`** : How the waterpoint is managed : GROUPED CLASS OF **`management`** FIELD\n",
    "    * user-group\n",
    "    * commercial\n",
    "    * [parastatal](https://www.collinsdictionary.com/dictionary/english/parastatal)\n",
    "    * other\n",
    "    * unknown\n",
    "* **`payment`** : Whether the water is paid for and how : DETAIL OF **`payment_type`** FIELD\n",
    "    * never pay\n",
    "    * pay per bucket\n",
    "    * pay monthly\n",
    "    * pay when scheme fails\n",
    "    * pay annually\n",
    "    * other\n",
    "    * unknown\n",
    "* **`payment_type`** : Whether the water is paid for and how : GROUPED CLASS OF **`payment`** FIELD\n",
    "    * never pay\n",
    "    * per bucket\n",
    "    * monthly\n",
    "    * on failure\n",
    "    * annually\n",
    "    * other\n",
    "    * unknown\n",
    "* **`water_quality`** : The quality of the water : DETAIL OF **`quality_group`** FIELD\n",
    "    * soft\n",
    "    * salty\n",
    "    * soft\n",
    "    * salty\n",
    "    * milky\n",
    "    * coloured\n",
    "    * salty abandoned\n",
    "    * fluoride\n",
    "    * flouride abandoned\n",
    "    * unknown\n",
    "* **`quality_group`** : The quality of the water : GROUPED CLASS OF **`water_quality`** FIELD\n",
    "    * good\n",
    "    * salty\n",
    "    * milky\n",
    "    * colored\n",
    "    * fluoride\n",
    "    * unknown\n",
    "* **`quantity`** : The quantity of water : DETAIL OF **`quantity_group`** FIELD\n",
    "    * enough\n",
    "    * insufficient\n",
    "    * dry\n",
    "    * seasonal\n",
    "    * unknown\n",
    "* **` quantity_group`** : The quantity of water : GROUPED CLASS OF **`quantity`** FIELD\n",
    "    * enough\n",
    "    * insufficient\n",
    "    * dry\n",
    "    * seasonal\n",
    "    * unknown\n",
    "* **`source`** : The source of the water : DETAIL OF **`source_type`** FIELD\n",
    "    * spring\n",
    "    * shallow well\n",
    "    * machine dbh\n",
    "    * river\n",
    "    * rainwater harvesting\n",
    "    * hand dtw\n",
    "    * lake\n",
    "    * dam\n",
    "    * other\n",
    "    * unknown\n",
    "* **`source_type`** : The source of the water : GROUPED CLASS OF **`source`** FIELD\n",
    "    * spring\n",
    "    * shallow well\n",
    "    * borehole\n",
    "    * river/lake\n",
    "    * rainwater harvesting\n",
    "    * dam\n",
    "    * other\n",
    "* **`source_class`** : The source of the water\n",
    "    * groundwater\n",
    "    * surface\n",
    "    * unknown\n",
    "* **`waterpoint_type`** : The kind of waterpoint : DETAIL OF **`waterpoint_type_group`** FIELD\n",
    "    * communal standpipe\n",
    "    * hand pump\n",
    "    * communal standpipe multiple\n",
    "    * improved spring\n",
    "    * cattle trough\n",
    "    * dam\n",
    "    * other    \n",
    "* **`waterpoint_type_group`** : The kind of waterpoint : GROUPED CLASS OF **`waterpoint_type`** FIELD\n",
    "    * communal standpipe\n",
    "    * hand pump\n",
    "    * improved spring\n",
    "    * cattle trough\n",
    "    * dam\n",
    "    * other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"data-preprocessing\"></a>\n",
    "### 2C. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate records in the waterpoints dataframe\n",
    "len(waterpoints[waterpoints.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate records in the waterpoints status dataframe\n",
    "len(waterpoints_status[waterpoints_status.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing, converting data types and handling missing data\n",
    "waterpoints['construction_year'] = waterpoints['construction_year'].fillna(0).astype(int)\n",
    "\n",
    "# Create additional field to categorise the age of the waterpoint\n",
    "age_conditions = [\n",
    "    (waterpoints['construction_year'] >= 2000),\n",
    "    (waterpoints['construction_year'] >= 1990) & (waterpoints['construction_year'] <= 1999),\n",
    "    (waterpoints['construction_year'] >= 1980) & (waterpoints['construction_year'] <= 1989),\n",
    "    (waterpoints['construction_year'] >= 1970) & (waterpoints['construction_year'] <= 1979),\n",
    "    (waterpoints['construction_year'] >= 1960) & (waterpoints['construction_year'] <= 1969),\n",
    "    (waterpoints['construction_year'] == 0)]\n",
    "age_values = ['5-noughties','4-nineties','3-eighties','2-seventies','1-sixties','0-unknown']\n",
    "waterpoints['construction_decade'] = np.select(age_conditions, age_values)\n",
    "waterpoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined dataframe of waterpoints and status\n",
    "waterpoints_with_status = pd.merge(left=waterpoints, \n",
    "                                   right=waterpoints_status, \n",
    "                                   left_on='id', \n",
    "                                   right_on='id')\n",
    "waterpoints_with_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional field to convert the status group to an integer\n",
    "status_conditions = [\n",
    "    (waterpoints_with_status['status_group'] == 'non functional'),\n",
    "    (waterpoints_with_status['status_group'] == 'functional'),\n",
    "    (waterpoints_with_status['status_group'] == 'functional needs repair')]\n",
    "status_values = [0, 1, 2]\n",
    "waterpoints_with_status['status'] = np.select(status_conditions, status_values)\n",
    "waterpoints_with_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific columns where data is either significantly incomplete, duplicated or of a little value to the model.\n",
    "waterpoints_processed = waterpoints_with_status.drop([\n",
    "    'amount_tsh',\n",
    "    'date_recorded',\n",
    "    'funder',\n",
    "    'scheme_management',\n",
    "    'installer',\n",
    "    'wpt_name',\n",
    "    'num_private',\n",
    "    'subvillage',\n",
    "    'region_code',\n",
    "    'district_code',\n",
    "    'lga',\n",
    "    'ward',\n",
    "    'population',\n",
    "    'public_meeting',\n",
    "    'recorded_by',\n",
    "    'scheme_name',\n",
    "    'permit',\n",
    "    'construction_year',\n",
    "    'extraction_type',\n",
    "    'extraction_type_group',\n",
    "    'management',\n",
    "    'payment',\n",
    "    'water_quality',\n",
    "    'quantity',\n",
    "    'source',\n",
    "    'waterpoint_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterpoints_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"data-visualisations\"></a>\n",
    "### 2D. Data Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe specifically for the data visualisations as some additional processing steps will arise as \n",
    "# a result and drop unnecessary columns.\n",
    "waterpoints_visuals = waterpoints_with_status.drop([\n",
    "    'amount_tsh',\n",
    "    'date_recorded',\n",
    "    'funder',\n",
    "    'gps_height',\n",
    "    'installer',\n",
    "    'wpt_name',\n",
    "    'num_private',\n",
    "    'basin',\n",
    "    'subvillage',\n",
    "    'region_code',\n",
    "    'district_code',\n",
    "    'lga',\n",
    "    'ward',\n",
    "    'population',\n",
    "    'public_meeting',\n",
    "    'recorded_by',\n",
    "    'scheme_name',\n",
    "    'permit',\n",
    "    'construction_year',\n",
    "    'extraction_type',\n",
    "    'extraction_type_group',\n",
    "    'management',\n",
    "    'payment',\n",
    "    'water_quality',\n",
    "    'quantity',\n",
    "    'source',\n",
    "    'waterpoint_type'], axis=1)\n",
    "\n",
    "waterpoints_visuals = waterpoints_visuals[(waterpoints_visuals['waterpoint_type_group'] != 'cattle trough')]\n",
    "\n",
    "# One hot encode the waterpoint status but don't drop first as this is only for visualisation purposes \n",
    "status_group_dummies = pd.get_dummies(waterpoints_visuals['status_group'], drop_first=False, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_type_chart_data = pd.concat([waterpoints_visuals['source_type'], status_group_dummies], axis=1)\n",
    "source_type_chart_data = source_type_chart_data.set_index('source_type').groupby('source_type').sum()\n",
    "\n",
    "# Add \"total\" column and sort the dataframe based on the total number of waterpoints in descending order\n",
    "source_type_chart_data[\"total\"] = (source_type_chart_data['functional'] +\n",
    "                                   source_type_chart_data['functional needs repair'] +\n",
    "                                   source_type_chart_data['non functional'])\n",
    "  \n",
    "source_type_chart_data = source_type_chart_data.sort_values(\"total\", ascending=False)\n",
    "source_type_chart_data = source_type_chart_data.drop(\"total\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart to display the number of waterpoints by source type with status\n",
    "x_labels = ['Spring','Shallow Well','Borehole','River / Lake','Rainwater','Dam','Other']\n",
    "y_labels = ['0','2,000','4,000','6,000','8,000','10,000','12,000','14,000','16,000']\n",
    "\n",
    "ax = source_type_chart_data.plot(kind='bar', stacked=True, figsize=(15,9), width=0.8)\n",
    "ax.set_title('Waterpoint Status by Source Type', fontsize=18, pad=30)\n",
    "ax.set_xlabel('Source Type', fontsize=16, labelpad=16)\n",
    "ax.set_ylabel('Number of Waterpoints with Status', fontsize=16, labelpad=16)\n",
    "ax.set_xticklabels(x_labels, \n",
    "                   fontsize=14, \n",
    "                   rotation=0)\n",
    "ax.set_yticklabels(y_labels, \n",
    "                   fontsize=14)\n",
    "\n",
    "plt.legend(['Functional','Functional Needs Repair','Non Functional'], \n",
    "           bbox_to_anchor=(1.05, 1), \n",
    "           loc='upper left', \n",
    "           fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 100% stacked bar chart to display status of waterpoints by source type\n",
    "source_type_stacked = source_type_chart_data.apply(lambda x: x*100/sum(x), axis=1)\n",
    "\n",
    "x_labels = ['Spring','Shallow Well','Borehole','River / Lake','Rainwater','Dam','Other']\n",
    "y_labels = ['0%','20%,','40%','60%','80%','100%']\n",
    "\n",
    "ax = source_type_stacked.plot(kind='bar', stacked=True, figsize=(15,9), width=0.8)\n",
    "ax.set_title('Waterpoint Status by Source Type', fontsize=18, pad=30)\n",
    "ax.set_xlabel('Source Type', fontsize=16, labelpad=16)\n",
    "ax.set_ylabel('Percentage of Waterpoints by Status', fontsize=16, labelpad=16)\n",
    "ax.set_xticklabels(x_labels, \n",
    "                   fontsize=14, \n",
    "                   rotation=0)\n",
    "ax.set_yticklabels(y_labels, \n",
    "                   fontsize=14)\n",
    "\n",
    "plt.legend(['Functional','Functional Needs Repair','Non Functional'], \n",
    "           bbox_to_anchor=(1.05, 1), \n",
    "           loc='upper left', \n",
    "           fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "management_group_chart_data = pd.concat([waterpoints_visuals['management_group'], status_group_dummies], axis=1)\n",
    "management_group_chart_data = management_group_chart_data.set_index('management_group').groupby('management_group').sum()\n",
    "\n",
    "# Add \"total\" column and sort the dataframe based on the total number of waterpoints in descending order\n",
    "management_group_chart_data[\"total\"] = (management_group_chart_data['functional'] +\n",
    "                                        management_group_chart_data['functional needs repair'] +\n",
    "                                        management_group_chart_data['non functional'])\n",
    "  \n",
    "management_group_chart_data = management_group_chart_data.sort_values(\"total\", ascending=False)\n",
    "management_group_chart_data = management_group_chart_data.drop(\"total\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart to display the number of waterpoints by management group with status\n",
    "x_labels = ['User Group','Commercial','Parastatal','Other','Unknown']\n",
    "y_labels = ['0','10,000','20,000','30,000','40,000','50,000']\n",
    "\n",
    "ax = management_group_chart_data.plot(kind='bar', stacked=True, figsize=(15,9), width=0.8)\n",
    "ax.set_title('Waterpoint Status by Management Group', fontsize=18, pad=30)\n",
    "ax.set_xlabel('Management Group', fontsize=16, labelpad=16)\n",
    "ax.set_ylabel('Number of Waterpoints by Status', fontsize=16, labelpad=16)\n",
    "ax.set_xticklabels(x_labels, \n",
    "                   fontsize=14, \n",
    "                   rotation=0)\n",
    "ax.set_yticklabels(y_labels, \n",
    "                   fontsize=14)\n",
    "\n",
    "plt.legend(['Functional','Functional Needs Repair','Non Functional'], \n",
    "           bbox_to_anchor=(1.05, 1), \n",
    "           loc='upper left', \n",
    "           fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 100% stacked bar chart to display status of waterpoints by management group\n",
    "management_group_stacked = management_group_chart_data.apply(lambda x: x*100/sum(x), axis=1)\n",
    "\n",
    "x_labels = ['User Group','Commercial','Parastatal','Other','Unknown']\n",
    "y_labels = ['0%','20%,','40%','60%','80%','100%']\n",
    "\n",
    "ax = management_group_stacked.plot(kind='bar', stacked=True, figsize=(15,9), width=0.8)\n",
    "ax.set_title('Waterpoint Status by Management Group', fontsize=18, pad=30)\n",
    "ax.set_xlabel('Management Group', fontsize=16, labelpad=16)\n",
    "ax.set_ylabel('Percentage of Waterpoints by Status', fontsize=16, labelpad=16)\n",
    "ax.set_xticklabels(x_labels, \n",
    "                   fontsize=14, \n",
    "                   rotation=0)\n",
    "ax.set_yticklabels(y_labels, \n",
    "                   fontsize=14)\n",
    "\n",
    "plt.legend(['Functional','Functional Needs Repair','Non Functional'], \n",
    "           bbox_to_anchor=(1.05, 1), \n",
    "           loc='upper left', \n",
    "           fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_type_chart_data = pd.concat([waterpoints_visuals['extraction_type_class'], status_group_dummies], axis=1)\n",
    "extraction_type_chart_data = extraction_type_chart_data.set_index('extraction_type_class').groupby('extraction_type_class').sum()\n",
    "\n",
    "# Add \"total\" column and sort the dataframe based on the total number of waterpoints in descending order\n",
    "extraction_type_chart_data[\"total\"] = (extraction_type_chart_data['functional'] +\n",
    "                                       extraction_type_chart_data['functional needs repair'] +\n",
    "                                       extraction_type_chart_data['non functional'])\n",
    "  \n",
    "extraction_type_chart_data = extraction_type_chart_data.sort_values(\"total\", ascending=False)\n",
    "extraction_type_chart_data = extraction_type_chart_data.drop(\"total\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart to display the number of waterpoints by extraction type class with status\n",
    "x_labels = ['Gravity','Handpump','Other','Submersible','Motorpump','Rope Pump','Wind Powered']\n",
    "y_labels = ['0','5,000','10,000','15,000','20,000','25,000']\n",
    "\n",
    "ax = extraction_type_chart_data.plot(kind='bar', stacked=True, figsize=(15,9), width=0.8)\n",
    "ax.set_title('Waterpoint Status by Extraction Type Class', fontsize=18, pad=30)\n",
    "ax.set_xlabel('Management Group', fontsize=16, labelpad=16)\n",
    "ax.set_ylabel('Number of Waterpoints by Status', fontsize=16, labelpad=16)\n",
    "ax.set_xticklabels(x_labels, \n",
    "                   fontsize=14, \n",
    "                   rotation=0)\n",
    "ax.set_yticklabels(y_labels, \n",
    "                   fontsize=14)\n",
    "\n",
    "plt.legend(['Functional','Functional Needs Repair','Non Functional'], \n",
    "           bbox_to_anchor=(1.05, 1), \n",
    "           loc='upper left', \n",
    "           fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 100% stacked bar chart to display status of waterpoints by extraction type\n",
    "extraction_type_stacked = extraction_type_chart_data.apply(lambda x: x*100/sum(x), axis=1)\n",
    "extraction_type_stacked.plot(kind='bar', stacked=True, figsize=(15,9), width=0.8)\n",
    "plt.title('Waterpoint Status by Extraction Type', fontsize=18, pad=30)\n",
    "plt.xlabel('Extraction Type', fontsize=16, labelpad=16)\n",
    "plt.xticks(fontsize=14, \n",
    "           rotation=0)\n",
    "plt.ylabel('% of Waterpoints by Status', fontsize=16, labelpad=16)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(['Functional','Functional Needs Repair','Non Functional'], \n",
    "           bbox_to_anchor=(1.05, 1), \n",
    "           loc='upper left', \n",
    "           fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "construction_decade_chart_data = pd.concat([waterpoints_visuals['construction_decade'], status_group_dummies], axis=1).set_index('construction_decade').groupby('construction_decade').sum()\n",
    "\n",
    "# Create a 100% stacked bar chart to display status of waterpoints by decade of construction\n",
    "construction_decade_stacked = construction_decade_chart_data.apply(lambda x: x*100/sum(x), axis=1)\n",
    "construction_decade_stacked.plot(kind='bar', stacked=True, figsize=(15,9), width=0.8)\n",
    "plt.title('Waterpoint Status by Construction Decade', fontsize=18, pad=30)\n",
    "plt.xlabel('Construction Decade', fontsize=16, labelpad=16)\n",
    "plt.xticks(fontsize=13, \n",
    "           rotation=0)\n",
    "plt.ylabel('% of Waterpoints by Status', fontsize=16, labelpad=16)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.legend(['Functional','Functional Needs Repair','Non Functional'], bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=13)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_group_chart_data = pd.concat([waterpoints_visuals['quantity_group'], status_group_dummies], axis=1)\n",
    "quantity_group_chart_data = quantity_group_chart_data.set_index('quantity_group').groupby('quantity_group').sum()\n",
    "\n",
    "# Add \"total\" column and sort the dataframe based on the total number of waterpoints in descending order\n",
    "quantity_group_chart_data[\"total\"] = (quantity_group_chart_data['functional'] +\n",
    "                                      quantity_group_chart_data['functional needs repair'] +\n",
    "                                      quantity_group_chart_data['non functional'])\n",
    "  \n",
    "quantity_group_chart_data = quantity_group_chart_data.sort_values(\"total\", ascending=False)\n",
    "quantity_group_chart_data = quantity_group_chart_data.drop(\"total\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart to display the number of waterpoints by quantity group with status\n",
    "x_labels = ['Enough','Insufficient','Dry','Seasonal','Unknown']\n",
    "y_labels = ['0','5,000','10,000','15,000','20,000','25,000','30,000']\n",
    "\n",
    "ax = quantity_group_chart_data.plot(kind='bar', stacked=True, figsize=(15,9), width=0.8)\n",
    "ax.set_title('Waterpoint Status by Quantity Group', fontsize=18, pad=30)\n",
    "ax.set_xlabel('Quantity Group', fontsize=16, labelpad=16)\n",
    "ax.set_ylabel('Number of Waterpoints by Status', fontsize=16, labelpad=16)\n",
    "ax.set_xticklabels(x_labels, \n",
    "                   fontsize=14, \n",
    "                   rotation=0)\n",
    "ax.set_yticklabels(y_labels, \n",
    "                   fontsize=14)\n",
    "\n",
    "plt.legend(['Functional','Functional Needs Repair','Non Functional'], \n",
    "           bbox_to_anchor=(1.05, 1), \n",
    "           loc='upper left', \n",
    "           fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"modelling\"></a>\n",
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries for modelling\n",
    "import statsmodels as sm\n",
    "import statsmodels.api as sm\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"logistic-regression\"></a>\n",
    "### 3A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterpoints_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = ['basin',\n",
    "              'region',\n",
    "              'extraction_type_class',\n",
    "              'management_group',\n",
    "              'payment_type',\n",
    "              'quality_group',\n",
    "              'quantity_group',\n",
    "              'source_type',\n",
    "              'waterpoint_type_group',\n",
    "              'construction_decade']\n",
    "\n",
    "# Create dummy variables - no need to normalise as everything is already on the same scale\n",
    "X = pd.get_dummies(waterpoints_processed[x_features], drop_first=True, dtype=float)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target variable\n",
    "y = waterpoints_processed['status']\n",
    "\n",
    "# Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create multinomial / multiclass logisitic regression model\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42)\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_hat_test)\n",
    "print('Confusion Matrix:\\n', cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['non functional', 'functional', 'functional needs repair']\n",
    "print(classification_report(y_train, y_hat_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of 71% for the Logistic regression model which is a good start for an initial, basic.  Achieves an accuracy of 72% for the test data suggesting that the model is not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bagged-tree\"></a>\n",
    "### 3B. Bagged Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree =  BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=5), n_estimators=20)\n",
    "\n",
    "bagged_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"random-forest\"></a>\n",
    "### 3C. Random Forest using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "mean_rf_cv_score = np.mean(cross_val_score(rf_clf, X_train, y_train, cv=3))\n",
    "\n",
    "print(f\"Mean Cross Validation Score for Random Forest Classifier: {mean_rf_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter grid and use GridSearchCV to find optimal parameters\n",
    "rf_param_grid = {\n",
    "    'n_estimators' : [10, 30, 100],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [None, 2, 6, 10],\n",
    "    'min_samples_split' : [5, 10],\n",
    "    'min_samples_leaf' : [3, 6]\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(rf_clf, rf_param_grid, cv=3)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Validation Accuracy: {rf_grid_search.best_score_ :.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_score = rf_grid_search.score(X_test, y_test)\n",
    "\n",
    "print('Random forest grid search: ', rf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"xgboost\"></a>\n",
    "### 3D. XGBoost with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "training_preds = clf.predict(X_train)\n",
    "val_preds = clf.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation Accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    \"learning_rate\": [0.1],\n",
    "    'max_depth': [6],\n",
    "    'min_child_weight': [10],\n",
    "    'subsample': [0.7],\n",
    "    'n_estimators': [5, 30, 100],\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(clf, xgb_param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_clf.predict(X_train)\n",
    "val_preds = grid_clf.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"svm\"></a>\n",
    "### 3E. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC(kernel='poly', decision_function_shape='ovo', cache_size=500)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"modelling-summary\"></a>\n",
    "### 3F. Modelling Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_features =  'basin',\n",
    "              'region',\n",
    "              'extraction_type_class',\n",
    "              'quality_group',\n",
    "              'quantity_group',\n",
    "              'source_type',\n",
    "              'waterpoint_type_group',\n",
    "              'construction_decade'\n",
    "              \n",
    "Logistic Regression = 71%\n",
    "Random Forest = 75%\n",
    "XGBoost = 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"competition-submission-file\"></a>\n",
    "## 4. Competition Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the test set of waterpoints data file from the repository\n",
    "submit_waterpoints = pd.read_csv('test-set-values.csv')\n",
    "\n",
    "# Data preprocessing, converting data types and handling missing data as above\n",
    "submit_waterpoints['construction_year'] = submit_waterpoints['construction_year'].fillna(0).astype(int)\n",
    "\n",
    "# Create additional field to categorise the age of the waterpoint\n",
    "age_conditions = [\n",
    "    (submit_waterpoints['construction_year'] >= 2000),\n",
    "    (submit_waterpoints['construction_year'] >= 1990) & (submit_waterpoints['construction_year'] <= 1999),\n",
    "    (submit_waterpoints['construction_year'] >= 1980) & (submit_waterpoints['construction_year'] <= 1989),\n",
    "    (submit_waterpoints['construction_year'] >= 1970) & (submit_waterpoints['construction_year'] <= 1979),\n",
    "    (submit_waterpoints['construction_year'] >= 1960) & (submit_waterpoints['construction_year'] <= 1969),\n",
    "    (submit_waterpoints['construction_year'] == 0)]\n",
    "age_values = ['5-noughties','4-nineties','3-eighties','2-seventies','1-sixties','0-unknown']\n",
    "submit_waterpoints['construction_decade'] = np.select(age_conditions, age_values)\n",
    "\n",
    "# Drop fields that aren't used by the model to produce a prediction\n",
    "submit_waterpoints = submit_waterpoints.drop([\n",
    "    'amount_tsh',\n",
    "    'date_recorded',\n",
    "    'funder',\n",
    "    'scheme_management',\n",
    "    'installer',\n",
    "    'wpt_name',\n",
    "    'num_private',\n",
    "    'subvillage',\n",
    "    'region_code',\n",
    "    'district_code',\n",
    "    'lga',\n",
    "    'ward',\n",
    "    'population',\n",
    "    'public_meeting',\n",
    "    'recorded_by',\n",
    "    'scheme_name',\n",
    "    'permit',\n",
    "    'construction_year',\n",
    "    'extraction_type',\n",
    "    'extraction_type_group',\n",
    "    'management',\n",
    "    'payment',\n",
    "    'water_quality',\n",
    "    'quantity',\n",
    "    'source',\n",
    "    'waterpoint_type'], axis=1)\n",
    "\n",
    "# One hot encode categorical data for submission dataset in order to produce predictions\n",
    "X_submit = pd.get_dummies(submit_waterpoints[x_features], drop_first=True, dtype=float)\n",
    "# X_submit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(output_filename, model_name):\n",
    "    submission_values = pd.DataFrame()\n",
    "    submission_values['status'] = model_name.predict(X_submit)\n",
    "    submission_data = pd.concat([submit_waterpoints['id'], submission_values], axis=1)\n",
    "    status_conditions = [\n",
    "    (submission_data['status'] == 0),\n",
    "    (submission_data['status'] == 1),\n",
    "    (submission_data['status'] == 2)]\n",
    "    status_values = ['non functional', 'functional', 'functional needs repair']\n",
    "    submission_data['status_group'] = np.select(status_conditions, status_values)\n",
    "    submission_data = submission_data.drop(['status'], axis=1)\n",
    "    submission_data.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_submission_file('svm-submission-4.csv', svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
